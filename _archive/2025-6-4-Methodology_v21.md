---
# all the regular stuff you have here
zotero:
  scannable-cite: false # only relevant when your compiling to scannable-cite .odt
  client: zotero # defaults to zotero
  author-in-text: false # when true, enabled fake author-name-only cites by replacing it with the text of the last names of the authors
  csl-style: harvard-manchester-metropolitan-university # pre-fill the style
layout: post
categories: chapter
title: 4. Methodology
---
-   [Methodology](#methodology)
    -   [Introduction](#introduction)
        -   [Research design and alignment with
            questions](#research-design-and-alignment-with-questions)
        -   [Reflections on theoretical grounding and research
            design](#reflections-on-theoretical-grounding-and-research-design)
    -   [Data collection within project delivery
        phases](#data-collection-within-project-delivery-phases)
        -   [Data collection methods and their integration with project
            delivery](#data-collection-methods-and-their-integration-with-project-delivery)
    -   [Reflections on methodological
        approach](#reflections-on-methodological-approach)
        -   [The use of holistic data and rich
            descriptions](#the-use-of-holistic-data-and-rich-descriptions)
        -   [Utility and replicability](#utility-and-replicability)
        -   [Ethical considerations](#ethical-considerations)
    -   [Data analysis process](#data-analysis-process)
        -   [Stage 1 -- Exploratory
            analysis](#stage-1-exploratory-analysis)
        -   [Stage 2 -- Thematic
            Refinement](#stage-2-thematic-refinement)
        -   [Stage 3 -- Interpretive
            Consolidation](#stage-3-interpretive-consolidation)
            -   [Design narrative as interpretive
                structure](#design-narrative-as-interpretive-structure)
            -   [Use of 3GAT analysis](#use-of-3gat-analysis)
        -   [Diagrammatic representations - Drop, move or
            keep?](#diagrammatic-representations---drop-move-or-keep)
            -   [GDPs as a germ cell in design and
                analysis](#gdps-as-a-germ-cell-in-design-and-analysis)
            -   [Analysing learner agency](#analysing-learner-agency)
    -   [Researcher stance and interpretive
        validity](#researcher-stance-and-interpretive-validity)
        -   [Triangulation and analytic
            trustworthiness](#triangulation-and-analytic-trustworthiness)
        -   [Generalisability and
            replication](#generalisability-and-replication)
        -   [Methodological and practical
            limitations](#methodological-and-practical-limitations)
        -   [Wider limitations](#wider-limitations)
    -   [Chapter conclusion](#chapter-conclusion)
    -   [Footnotes](#footnotes)


# Methodology



## Introduction



This chapter sets out the methodological approach underpinning the study, building on the theoretical commitments explored in Chapter 3. Drawing on activity theory and design-based research (DBR), the research was conducted as an iterative process embedded in a  non-formal learning environment in a home education and university partnership. Rather than applying a fixed method to a controlled setting, the study developed responsively, shaped by the interplay of context, participant contributions, and pedagogical experimentation. Chapter 3 introduced the conceptual foundations that informed this approach: learning as socially and historically situated, agency as emergent and distributed, and design as a catalyst for transformation. These ideas are translated here into a methodological approach, particularly a focus on mutual engagement with participants, flexibility in pedagogical design, and responsiveness to evolving dynamics within the setting.

The chapter begins by situating the study as qualitative and exploratory in character. It outlines the delivery of the intervention and the diverse data collection methods used throughout, including video capture, screen recordings, facilitator journals, interviews, and artefact analysis. These activities are described in relation to the five delivery phases of the programme, showing how participants shaped both the content and direction of the study. This is followed by a discussion of ethical considerations, including recruitment, consent, and the handling of non-anonymisable data such as video recordings.

The next section details the analytical process, which developed across three broad stages: initial exploratory review, thematic refinement, and interpretive consolidation. Each stage is linked to core analytic concepts from DBR and third-generation activity theory, including contradiction mapping, mediational analysis, and learner agency. Particular attention is given to gameplay design patterns (GDPs), which are interpreted as germ cells, small but generative design elements that supported shifts in participation and learning. The chapter concludes with a reflection on researcher stance, interpretive validity, and methodological limitations. These include constraints around generalisability and the challenges of working with large and complex data sets in informal settings.

This chapter uses a combination of in-text references and footnotes. In-text references are used for academic sources, while footnotes provide methodological context, link to appendices and vignettes, and refer to content from earlier chapters. This referencing approach is intended to support narrative flow while maintaining transparency.

### Research design and alignment with questions

In summary the research process was oriented around a series of weekly digital game making workshops for home educating young people and their parents or guardians. These sessions were organised into runs of between 5-10 weeks at the end of which a game was created to share publicly. The process of both educational facilitation and data collection was led by myself, and supported by student helpers[^sh]. This chapter outlines a methodological approach grounded in the general principles of formative interventions and design-based research (DBR). While the previous chapters have established the theoretical framework and research questions, this chapter connects those questions more directly to methods. To provide an overview to ground the reader, an outline how the research questions informed data collection, analysis, and theoretical framing follows:

<!--
To do this it will draw on techniques from those disciplines including .
specifically social design-based experiments (SDBE) and design-based implementation research (DBIR) [@penuel_design-based_2021] -->



**RQ1**: *What contradictions emerged during participation in CGD&P activities, and how were they addressed via an innovative pedagogy?*  
Data were drawn from facilitator reflections,  participant and practitioner interviews, and video observations. These were analysed through systemic tension mapping and activity system analysis, using cultural-historical activity theory (CHAT) to frame contradictions as drivers of expansive transformation.

**RQ2**: *How can a collection of game design patterns support CGD&P, particularly regarding abstract and concrete dimensions of existing pedagogies?*  
Data included screen capture analysis,  documentation emerging from the research intervention, and participant interviews reflecting on game design pattern use. Thematic analysis focused on mediation through game design patterns and how these related to shifts in learning activity. The framing of the findings drew on the mediational lens of CHAT and the pedagogical scaffolding emphasis of DBR.

**RQ3**: *How do learner agency and game-maker identity develop within CGD&P communities of practice, and what pedagogical strategies best support this evolution across diverse learning contexts?*  
A dataset spanning phases of community interactions and design development, interviews, and field notes was analysed through thematic clustering, relational mapping, and narrative analysis. This was informed by DBR’s emphasis on iterative refinement and 3GAT’s view of expansive learning in situated activity which draws on practices from interconnected activity systems.



### Reflections on theoretical grounding and research design

This study is qualitative, general, and exploratory in nature, shaped by DBR and CHAT. It adopts an iterative, context-sensitive approach to understanding learning environments in CGD&P, avoiding rigid experimental constraints. In terms of educational objectives, the goal is to generate situated knowledge that can inform responsive educational practices rather than to produce more universally generalisable outcomes [@cobb_design_2003]. However, the methodology of this research also seeks to reveal pedagogical tensions, contradictions, and shifts in learner agency and develop understandings which have potential for a broader application.

In line with DBR approaches, rather than starting with fixed aims, the inquiry evolved through mutual engagement with participants and an openness to emergent goals [@gravemeijer2006design]. This orientation is justified both by the nature of the setting (non-formal, collaborative, and often resistant to conventional evaluation [@rogoff_observing_1995]) and by the desire to avoid prematurely deciding on what kinds of pedagogical or methodological innovations might arise. While certain pedagogical features remained consistent throughout, the process was fundamentally shaped by what unfolded during iterative cycles of engagement undertaken by the participants and facilitators with the changing learning environment and resources. The process of rapid and responsive iteration allowed refinement of learning materials in response to participant feedback and my systemic analysis in a way which leveraged the strengths of design-based approaches while aligning them with the insights offered by CHAT [@gutierrez_relevance_2014]. This flexible approach addresses both the complexities of authentic (as opposed to lab controlled conditions), non-formal learning contexts and the need for practical, and ideally replicable outcomes .

Pedagogical elements of the research design were  co-developed through collaboration with young learners, their families, and undergraduate student helpers. Over time, iterative design phases were informed by participant feedback, emergent needs, and reflection on practice [@visser_schon_2010; @schon_reflective_1984]. This collaborative shaping of both tools and pedagogy reflects established principles in participatory research [@iversen_computational_2018-1; @iivari_critical_2017], DBR [@barab_design-based_2004], and formative interventions [@cole_fifth_2006; @blunden_formative_2023].

Participant input took multiple forms: direct feedback through interviews and structured activities, observations of gameplay and design behaviour, and artefacts produced during workshops. Interviews and informal feedback were encounters through which participants helped shape the evolving design. This approach aligns with the sociocultural research methodology of Edwards [-edwards_being_2010-2] who frames interviews as potential sites of meaning-making and relational agency, rather than extractive processes. Most specifically, feedback from young participants, education student helpers, and parents contributed to iterative refinements in the software environments, templates, and facilitation strategies used in particular in Phase 1 and Phase 2. These evolving design decisions are documented throughout the study and explored further in Chapters 5 to 7.


<!-- Bakker offers guidance in the formulation of research questions in DBR studies which are relevant to this thesis [@bakker_design_2018]. He promotes HOW and WHAT CONSIDERATIONS formulation of question to be represent the exploratory nature of DBR approaches and to increase the possibility of possible generalisation without over promising in terms of projecting beyond the embedded nature of the findings as embedded in the context of the study. -->

## Data collection within project delivery phases

This section outlines the delivery of the game-making programme and the data collection activities embedded within each phase. While Chapter 5 explores the pedagogical evolution as a design narrative, the focus here is on data collection methods and how they supported analysis. In addition to participant-facing methods, a small number of interviews with creative computing practitioners were included to contextualise design decisions. The programme unfolded across five delivery phases, each marked by changes in group size, tools, and facilitation. Figure 4.x summarises these shifts.

<!-- From https://docs.google.com/presentation/d/1vR6dzFG6qXIdpB_-s6PbCePiB87qTs6YAXCljxNcb5Y/edit?slide=id.g2e34c54339d_0_0#slide=id.g2e34c54339d_0_0 -->

![](./Pictures/phases_diagram_chevrons_3.png){width=98%}

Figure 4.x Summary of delivery phases and development periods

<!-- **Development and recruitment** -->

The first development process of this study (D1) drew on a background context of my involvement in community-based technology education as outlined in Chapter 1. My involvement in previous work in university partnership programmes with informal education settings [^3] using playful technology meant that I had already built relationships with the home-educating community. Between 2016 and the start of this study, I had run various creative workshops in libraries, the university, and through informal volunteer events [^cdj]. To promote the university-based events I had used three established home education communication networks[^4]. The recruitment process of this study followed this previous pattern. I shared an invitation to participant to those three groups which asking interested families to contact me by email [^5]. Once contacted by potential participants, I sent them a participation sheet and asked for confirmation of attendance [^6].


Table 4.x summarises participant numbers, session counts, and key learning activities across each phase. Shifts in format and focus influenced both the type of data generated and the methods through which it could be collected.


| Phase | Sessions | Participants | Activities and data highlights |
|-------|----------|--------------|-------------------------------|
| **P1** | 10 | 5 parents, 8 children | **Exploratory group phase.** Mixed-age groups engaged in paper-based planning, introductory coding with a text-based tool, and asset creation. Game files and design artefacts were collected. |
| **P2** | 6  | 8 parents, 11 children, 4 student helpers | **Smaller group development.** Participants used a shared coding template and printed guides. Asset creation was less central to the process. |
| **P3** | 5  | 4 parents, 8 children, 1 student helper | **Drama-integrated learning.** Continued with the same coding setup, enriched by additional missions to encourage social interaction and drama-based narrative. |
| **P4** | 6  | 4 parents, 7 children | **Toolset shift.** MakeCode (block-based) was introduced [^7].  |
| **P5** | 5  | 3 parents, 3 children | **Personalised learning.** A smaller group continued using MakeCode, with additional support from new learning resources created in D3|

Table 4.x: Summary of delivery phases

<!--
| Phase | Sessions | Participants | Key learning activities and data generated |
|-------|----------|--------------|--------------------------------------------|
| P1    | 10       | 5 (p) + 8 (c) | Exploratory phase with three larger groups of mixed ages. Data includes paper-based planning, basic coding using a text-based toolset, and early asset creation. Game files and code were collected. See Appendix t.x. |
| P2    | 6        | 8 (p) + 11 (c) + 4 (sh) | Groups became smaller and more focused. A shared template supported game development. Asset creation was more limited, but participants used printed guides extensively. [^3] |
| P3    | 5        | 4 (p) + 8 (c) + 1 (sh) | Same coding environment as in P2. Additional drama activities and side missions were introduced. See Appendix t.x. |
| P4    | 6        | 4 (p) + 7 (c) | MakeCode, a block-based toolset[^4], was introduced and used throughout. Sessions became more modular. See Appendix t.x. |
| P5    | 5        | 3 (p) + 3 (c) | A smaller cohort continued to use MakeCode, focusing on individual and pair-based work. See Appendix t.x. | -->

A second table presents a consolidated view of the data sources used in the study, detailing how each was collected and which phases it applied to.

| **Data source**             | **Details**                         | **Description**                                                                                         | **Used in which phases** |
|----------------------------|-------------------------------------|----------------------------------------------------------------------------------------------------------|---------------------------|
| Screen capture recordings  | 72 recordings from 12 sessions      | Recorded using Flashback Pro, including video, audio, mouse activity, and keystrokes.                    | P2, P3, P4, P5            |
| 360° video recordings       | 9 recordings from 9 sessions        | Captured using a Samsung Gear 360° camera. Stored on SD cards and processed via custom workflow.         | P2, P3, P4                |
| Facilitator journal entries| 3 paper journals and 50 digital pages | Included session planning, design sketches, reflections, and notes on challenges and evaluation.        | All phases                |
| Programme resources         | Varied (see Chapter 5)              | Materials co-developed with participants, including templates, guides, and scaffolds. Stored digitally.  | All phases                |
| Practitioner interviews[^piv]    | 4 interviews (~90 minutes each)    | Conducted via Zoom, recorded as video and audio files.                                                  | Post-P3 workshops         |
| Participant interviews      | 4 interviews (~90 minutes each)    | One via Zoom, three captured using screen recording with games and artefacts as prompts.                 | Post-P3 workshops         |



Data collection was embedded within the evolving delivery of the programme. Participant influence shaped resource development both directly (e.g. feedback and interviews) and indirectly (e.g. through gameplay choices and observed activity). These interactions were documented through facilitator journals, archived resources, and video data, each contributing to a evolving understanding of learning and design in practice.

Journal notes were kept throughout the process in both paper-based journals and chronologically organised Word documents. These included session reflections, notes on challenges in resource design, and responses to emerging themes from relevant research. Alongside this, I archived the digital resources used in each phase, including templates, guides, and the games and related assets created by the young participants[^itch]. The games themselves were treated as a form of data, drawing on activity theory's emphasis on tools as culturally mediated artefacts and the principle of double stimulation, where learners repurpose tools to support their own goals. Instances of adaptation beyond intended use were treated as significant moments within the evolving activity.

Video data played a key role in capturing situated activity: both 360° video data and screen capture data were recorded [^10]. Regarding computer screen capture, the software Flashback Pro was chosen for screen capture due to its accessibility and low cost. The software recorded user input and screen activity including data of mouse clicks and keyboard events [^11]. The use of 360° camera footage stemmed from two main considerations. Firstly, I wanted a fixed approach rather than a roaming attached device to avoid possible disorientation [@caton2019methodological], and I wanted to try to capture as little video data as practicable due to the high overhead of processing and interpreting it. Given this motivation, I avoided using individual webcams of the computers or several static cameras positioned in several locations in the room. Instead, I arranged the tables in a square with chairs on the outside facing inwards and positioned a 360° camera in the centre of this arrangement. This approach allowed the capture of whole-group interaction from a single fixed viewpoint. A still of the 360° footages (before processing) is shown in Figure 4.x.

![](./Pictures/360_smudge.png){width=98%}

Figure 4.x - 360° footage from the central camera (before processing)

While there is little written on the use of 360° video data in research [^36], the use of video cameras to capture social interactions in class room or non-formal educational settings is well explored through varied lenses, including: practicality of recording and representing video data of participant interactions [@plowman_big_2008], theoretical concerns [@flewitt_using_2006] and ethical issues particular to video data [@peters_video_2021]. Managing both set of video data involved careful planning. The large video files required consistent naming and regular backups. The 360° recordings were particularly complex, sometimes split into segments that made time navigation difficult. Specialised software from the camera manufacturer was needed to process the raw footage. To address these challenges, I developed a Linux-based workflow for organising and processing video and audio data, which is included in the technical appendix [^12].

Participant and practitioner interviews took place after Phase 3. These were semi-structured and conducted online due to practical and, at times, COVID-related constraints. To help participants recall information, during the interview process a laptop was on hand to allow them to revisit their created games games and assets to support their reflection on design choices and problem-solving strategies. Turning to interviews of fellow practitioners and researchers in the area of creating digital making, interviewees included Saskia Leggett, a researcher involved in the Creative Family Learning programme; Matt Curinga, an academic and educator active in community-based coding projects; Dave Potts, a professional programmer and long-term CoderDojo volunteer; and James Clegg, a PGCE computing student who had also supported sessions in person.

<!--
#### Summary of data collection methods

### Summary of data collection methods

| **Data source**                                | **Collected through**                                           | **Used to explore**                                               |
|------------------------------------------------|------------------------------------------------------------------|-------------------------------------------------------------------|
| Participant interaction with each other and digital software | 360° video and screen recordings                        | Learning processes, tool use, collaboration, agency              |
| Digital artefacts                              | Code files, resulting games, graphical assets, physical sketches | Participant responses to design tools and creative direction     |
| Facilitator journal                            | Reflexive notes during and after sessions                       | Researcher stance, contradiction surfacing, pedagogical choices  |
| Participant interviews                         | Paired or individual interviews with learners (audio-recorded)  | Reflections on design decisions, perceived agency, collaboration |
| Practitioner interviews                        | Audio-recorded interviews with facilitators from similar non-formal creative coding settings     | Existing facilitation strategies, contexual tensions, participant roles and identities      |


Revised more detail.

| **Data source**           | **Collection method**                                | **Volume / Scope**                              | **Analytic purpose and framing**                                               |
|--------------------------|-------------------------------------------------------|--------------------------------------------------|---------------------------------------------------------------------------------|
| 360° video recordings     | Fixed Samsung Gear 360° camera                        | 9 recordings across P2–P4                        | Group interaction, gesture, peer mediation (Rogoff, CHAT)                      |
| Screen recordings         | Flashback Pro with input/audio capture               | 72 recordings across 12 sessions (P2–P5)         | Tool use, coding navigation, contradiction (CHAT, mediation)                  |
| Facilitator journal       | Paper notes and digital Word docs                    | 3 paper journals + 50 digital pages              | Researcher stance, design changes, contradiction surfacing (DBR, CHAT)         |
| Participant interviews    | Semi-structured with game artefacts for prompting    | 4 interviews (~90 mins each)                     | Perceived agency, collaboration, design reflection (agency theory, CHAT)       |
| Practitioner interviews   | Zoom interviews with informal educators              | 4 interviews (~90 mins each)                     | Facilitation strategies, contextual tensions (DBR, SDBE)                        |
| Digital artefacts         | Games, graphical assets, code files, sketches        | Collected across all phases                      | Creative responses, appropriation, problem-solving (germ cell, mediation)      |
| Programme resources       | Templates, guides, tools created during sessions     | Iteratively developed, stored digitally          | Evolution of scaffolds and pedagogy (design narrative, DBR, formative design)  |
 -->

## Reflections on methodological approach

This section reflects on key aspects of the study’s methodological approach, including its emphasis on rich description, practical relevance, and ethical practice in an non-formal, participatory learning context.


### Rich description and practical utility in a responsive research design

This study provides _thick_, descriptive accounts of learning in CGD&P across multiple levels of activity [@maxwell_qualitative_2013]. Informed by Rogoff’s [-@rogoff_observing_1995] three planes of analysis in communities of learners, data collection included both individual and group-level video capture, journal notes, screen recordings, and design artefacts. These layered sources enabled analysis of how learning processes unfolded across time, tools, and interactions. This approach also introduced challenges, particularly in managing and interpreting complex video data, which are discussed later in this chapter.

The commitment to rich description reflects not only an aim for analytical rigour, but also a desire to make the research relevant and applicable to other practitioners and researchers. This aligns with Brown’s original framing of design experiments as tools for addressing learning problems in authentic contexts [@brown_design_1992]. More recent work by Bakker [@bakker_design_2018] and Penuel [@penuel_design-based_2021] reinforces the idea that utility for future practice should be central to the design-based research process. Accordingly, this study emphasised design choices that supported adaptability and reuse across academic and informal learning settings.


One important aspect of this was the selection of tools and environments that were freely available or open-source. This was particularly relevant given the home education setting and the intended relevance of the work for other low-cost or under-resourced contexts. These decisions were informed by the concept of software sustainability in research [@crouch_software_2013] [^1] and the principles of open educational resource design [@bonneel_code_2020]. Wherever feasible, FLOSS (Free/Libre and Open Source Software) tools were used across both facilitation and analysis. This allowed the research process and learning design to remain transparent, shareable, and practically applicable beyond the original study site [^2].



### Ethical considerations

Ethical engagement is not only a requirement for doctoral research but a central concern in sociocultural research design. In this tradition, ethics are understood as embedded in relationships and shaped by context [@heath_ethnography_2010]. Ethical practice in educational research must take into account issues of power, particularly when working with children and families. In this section, and in line with a responsive approach to research, I outline both broad ethical concerns (approval processes, consent, withdrawal, data handling) as well as more specific issues that emerged during practice, including how participant relationships and reciprocity were navigated throughout the project [@hammersley_ethics_2012].

Ethical approval for this study was obtained through the ESRI ethics process using the ETHOS system. Participants were recruited via outreach to home education networks, coding events, and community meet-ups. Inclusion criteria included being part of a family unit (including guardians) who were able to travel to the Manchester Metropolitan University campus. Participating families included children aged approximately 7 to 13, and all participants needed sufficient English literacy to engage with written materials and communication. An expressed interest in learning to make digital games together as an educational project was also required.

Consent, assent, and autonomy were addressed through adapted processes. Consent and assent procedures were tailored for different participant groups, including home-educating families, children, and university students. For children, assent was negotiated through informal discussion followed by a simple written agreement, and parents remained nearby or directly involved throughout. DBS-checked adult facilitators and volunteers supported sessions, and alternative activities were always available to ensure that children could opt out at any time. These steps aimed to protect participant autonomy while recognising the relational dynamics of informal learning settings.

All video and screen data were stored on a password-protected external drive, separate from working research files [@wiles_anonymisation_2012]. Although the video data could not be fully anonymised at source, all analytic materials used pseudonyms and removed or blurred identifying visuals. Only the lead researcher had access to raw video data, though the approved ethics protocol allowed supervisors to view this material if necessary.

Withdrawal was handled with care across participant groups. Consent forms for practitioner-facilitators made clear that if they withdrew from the study, all data gathered would be destroyed and not analysed. For family participants, withdrawal procedures noted that data would no longer be analysed, but did not explicitly state that it would be destroyed. This distinction reflected the complex nature of group-based video data and the need to preserve the integrity of multi-participant recordings.

The challenges of ongoing consent were present  in this non-formal, multi-phase project. To support autonomy, consent forms included the wording “You will be able to continue with activities or equivalent activities,” emphasising that withdrawal from research would not mean exclusion from the educational opportunity. While no families withdrew from the research process, two families who participated in in the first part of Phase 1 did not continue into an extended period or later phases. I interpreted their withdrawal as an important way of communicating alienation from the game making process. One family returned to give feedback at the phase end and thus contributed to the research process in this way[^af].


Additional complexities emerged from the use of 360° video and screen recordings. While no families ultimately withdrew, the protocol specified that if they had, their data would no longer have been analysed. However, it would not have been destroyed — a departure from standard practice for individual data, where withdrawal typically requires deletion in line with ethical guidance from professional organisations [british_educational_research_association_bera__ethical_2018], which prioritises participant autonomy and control. This adaptation was necessary because it was not possible to fully remove a participant’s presence from 360° recordings that included other individuals. Group-based video data of this kind makes clean removal impractical without compromising the integrity of the dataset and the contributions of others. This limitation was outlined in the consent forms.


A separate issue arose in relation to missing screen recording data. For one family, end-of-session video captures were regularly absent. In one instance, a short clip showed the young person navigating away from the software. This could suggest a resistance to surveillance or a technical decision, as video capture software sometimes slowed down the game-making tools. Given the families on going participation in other aspects of the research, their on-going verbal assent to the research process, and the focus of the study on varied expressions of agency, I chose not to challenge the absence of recorded screen data during ongoing sessions.

Assessing risk throughout the research process was also essential [@hammersley2012risk]. While the overall activity of game making as a collaborative process was relatively low-risk in a physical or emotional sense, an ethical issue concerning home-educating families was the potential for alienation from learning to programme, or from engaging in a partnership educational setting (in this case at University). I addressed this through strategies aimed at creating an inclusive, welcoming educational environment, aligned with the underlying ethos of the research.

My approach to ethics was also shaped by values of reciprocity, drawn from prior community and activist work and its intersection with discourse within higher education on open educational practices [@cronin_openness_2017]. My ongoing volunteer participation in local, volunteer-run creative coding events helped to build trust and extend relationships beyond the confines of the study itself. These efforts aimed to support more equitable research relationships and ensure participants gained lasting value from their involvement. This community approach to knowledge generation raises questions regarding researcher positionality and data validity, which are taken up later in this chapter [@schiffer_issues_2020].

In relation to the tools and resources that emerged from the study, I aimed to embed reciprocity through openness and reuse. Game-making tools used in the project were open-source and freely accessible, enabling families to replicate and continue their projects independently. Supporting documentation and design prompts were shared online under an open educational resource (OER) licence [@wiley_defining_2018; @wiley_access_2014], making the materials broadly usable beyond the research. Diaz Eaton and colleagues [-@diaz_eaton_sustainability_2022] highlight the importance of OER as part of a sustainability-responsive approach from relevant stakeholders within the rapidly evolving landscape of STEM education. Given that the involvement of parents and young people from the home education and informal science education networks contributed to the resources that resulted, it follows that those outputs should be freely available to the same communities [@ivey_open_2024].

## Data analysis process

The analysis is presented here via three  broad and overlapping stages which took on an iterative approach: beginning with exploratory review, progressing through thematic refinement and methodological adjustment, and concluding with interpretive consolidation. Each stage involved increasing analytical granularity, using strategies suited to the shifting demands of the research. This structure also helped manage the substantial volume of video and screen capture data generated during the game-making sessions.

Before outlining the three stages, I introduce the key analytic concepts that shaped the identification and interpretation of episodes across the dataset. Contradictions within the activity system were treated as potential sources of learning and redesign. Drawing on third-generation activity theory (3GAT), these were identified through tensions between tools, roles, and goals. Mediating artefacts, including digital tools, gestures, and documentation, were examined for how they supported or disrupted emerging patterns of behaviour. Rogoff’s [@rogoff_observing_1995] model of personal, interpersonal, and cultural planes of analysis provided a framework for connecting individual actions to wider group practices,  through spreadsheet annotation increasingly detailed transcription of selected video data. A complex and shifting view of agency was needed to understand the experience of participants as learners redirected tasks, repurposed tools, or supported peers. Gameplay design patterns (GDPs) were analysed as potential germ cells, understood as small but generative design elements that supported developmental movement. Their uptake and reinterpretation offered insight into how learners engaged with the structure and flexibility of the learning environment. Describing the practical methods involved in the process of applying these strategies is complicated by the process of triangulating data. A summary table including the methods used is outline below.

<!--
| **Analytic strategy**        | **Based on**                          | **Purpose**                                           | **Theoretical lens**             |
|-----------------------------|---------------------------------------|------------------------------------------------------|----------------------------------|
| Spreadsheet annotation      | Partial transcript of speech and description of screen/room video        | To track episodes of interaction across Rogoff's planes             | Rogoff, CHAT                     |
| Contradiction mapping       | Journals, video data of  episodes & tool use        | To surface tensions and system-level disruptions     | CHAT (more specifically 3GAT)                      |
| Thematic refinement         | Recurring patterns across data types  | To group design tensions, participant strategies     | CHAT, DBR                        |
| Design narrative | Artefacts & journals & vignettes    | To trace learning and role shifts over time          | Expansive learning, germ cell concept  |
| Agency interpretation | Vignettes & journal notes     | To identify shifts in tool use, initiative, role-taking, & identity         | CHAT conceptions of agency       | -->

| **Analytic strategy**       | **Data sources**                                         | **Methods used**                                                      | **Purpose / Theoretical lens**                                  |
|-----------------------------|----------------------------------------------------------|------------------------------------------------------------------------|-----------------------------------------------------------------|
| Spreadsheet annotation      | Partial transcript, screen/room video                    | Spreadsheet logging, annotation, increasingly detailed transcription                | Track interaction across Rogoff's planes [-@rogoff_observing_1995] (Rogoff [-@rogoff_observing_1995], CHAT)         |
| Contradiction mapping       | Journals, video episodes, tool use                       | Identifying affordances within design & mapping tensions across their use as systematic elements                 | To surface systemic tensions as a potential source of change (CHAT, 3GAT)                       |
| Thematic analysis        | Patterns within video and interview data             | Pattern recognition, grouping themes across data sources                           | Identify participant strategies in navigating contradictions (CHAT, DBR)|
| Design narrative            | Artefacts, journals, vignettes                           | Narrative description of evolving learning design artefacts, reflexive journal analysis, triangulation of multiple sources of data    | Trace learning experience of participants including role shifts, allow replication of learning design (DBR, germ cell identification from 3GAT)|
| Agency analysis       | Vignettes, journal notes                                 | Detailed analysis of initiative, role-taking, peer support and development of existing and new repertoires         | Interpret shifts in identity and agency (CHAT interpretations of agency)        |


Table 4.x: Summary of data analysis methods

These concepts guided interpretation throughout the three stages that follow: exploratory analysis, thematic refinement, and interpretive consolidation.

### Stage 1 – Exploratory analysis

Stage 1 served as an exploratory review of the dataset to assess data quality, relevance, and initial themes. This included reviewing researcher journals, practitioner interviews, and preliminary video footage to develop a sense of the emerging pedagogical and methodological issues. The goal was to understand the types of contradictions and learning behaviours present, and to inform the next steps for more focused analysis. This phase aimed to determine which datasets merited deeper analysis and to refine the methodological processes for subsequent analytical stages, aligning with approaches of iterative refinement in DBR [@bikner-ahsbahs_introduction_2015-1]. In line with Saldaña’s [-@saldana_coding_2013] framing of exploratory coding as a process of sense-making and initial theme generation, this early phase was used to surface broad patterns.

Journal analysis provided a foundational perspective on facilitation and early thematic tensions. Given the breadth of journal data, a comprehensive thematic analysis and exhaustive coding were impractical; instead, insights were triangulated with findings from the literature review to expose key themes and contradictions in the evolving pedagogy. Rogoff’s [-@rogoff_observing_1995] three planes of sociocultural activity were particularly useful here, allowing reflections on facilitation to be categorised across personal, interpersonal, and institutional dimensions, a technique further refined by Morcom [-@morcom_scaffolding_2014]. Alongside journal entries, evolving teaching resources, participant-created games, and assets were examined to provide insight into how learners engaged with design elements, navigated constraints, and appropriated resources for their own purposes. The use of these materials informed subsequent iterations of facilitation and resource development, and contributed to the emergent facilitation strategy.

Early-stage video data also played an important role in shaping the direction of analysis. Selected screen capture and 360-degree recordings from P2, P3, and P4 were reviewed to assess both the technical quality and the analytic potential of the recordings. This initial dip into the archive helped establish a sense of session rhythms, emerging roles, and mediational practices. Rather than aiming for full transcription at this point, I made time-stamped observational notes to identify sequences that warranted closer attention in later phases. In some cases, 360° footage was cross-referenced with screen capture data to clarify gesture, spatial positioning, and collaboration dynamics.

Identifying affordances during analysis helped surface how tools and environments invited or constrained different forms of participation. This proved valuable in understanding how learners interpreted resources, negotiated constraints, and appropriated tools creatively. The selection and design of tools was informed by the concept of *affordances*, a term common in DBR and HCI [^hci], which refers to the perceived and actual possibilities for action enabled by an environment or artefact. Drawing on Kaptelinin and Nardi’s [-@kaptelinin_affordances_2012, p. 927] CHAT-informed perspective, affordances were understood here as “possibilities for human actions mediated by cultural means”. This framing supports analysis of how the software, resources, and documentation shaped participant activity, including how learners interpreted constraints, imagined alternatives, and repurposed tools. Notes within early spreadsheet-based analysis of affordances in tool design and selection formed a foundation for understanding how contradictions emerged and were addressed within the unfolding learning activity.

Practitioner interviews were used alongside journal reflections to identify key pedagogical concerns, barriers to participation, and evolving priorities within the learning design. While my broader stance as a researcher-practitioner is discussed later in this chapter, these interviews drew on the experience of a wider community of practitioners, helping to shape early analytic directions and strengthen the thematic framing of the design narrative [@cochran-smith_inquiry_2015]. Four extended interviews (averaging 90 minutes each) were conducted with professionals and collaborators from overlapping fields of creative computing and informal education. The semi-structured format allowed for responsive dialogue and surfaced themes such as learner identity, creative constraint, scaffolding strategies, and tensions specific to non-formal learning contexts. For example, agency emerged as a central concern in Dave Potts’ reflections on supporting participants’ own interests in digital making; Matt Curinga raised questions about the value and risks of entering external competitions; Saskia Leggett highlighted the supporting roles of parents; and James Clegg discussed the affordances of online toolsets and game mechanics as mediational strategies. These conversations also helped guide subsequent cycles of video analysis by informing early coding directions and refining the research questions.

This first stage set the foundation for later interpretive work by clarifying the practical constraints of the data, surfacing early thematic directions, and testing the viability of the use of each data source.


### Stage 2 – Thematic Refinement
Stage 2 focused on the targeted analysis of selected episodes from the dataset. This process involved both deductive and inductive reasoning. Deductively, the analysis was shaped by theoretical constructs from activity theory (particularly contradictions, mediation, and role negotiation), which guided what was examined in the data. At the same time, an inductive approach allowed openness to patterns that emerged unexpectedly, especially in how learners appropriated tools or responded to design constraints. This combination of approaches is consistent with interpretive qualitative analysis and iterative design-based research [@saldana_coding_2013; @barab_design-based_2004].

To support this dual approach, the original plan was to develop a structured coding schema that could enable both qualitative insight and basic quantification. NVivo, a qualitative-first analysis platform that also supports mixed-methods queries, was selected to apply a consistent thematic structure across video data, interviews, and journals. The coding framework was informed by relevant literature, practitioner interviews, and preliminary observations [@saldana_coding_2013]. NVivo allows researchers to code across multiple datasets and run queries, for example, to explore how much time participants spent on particular tasks or how frequently specific behaviours occurred [^14].

However, a number of challenges arose. Technically, NVivo was unable to import 360° footage in a way that supported effective cross-referencing with other data. It also lacked precision for playback and segment-level coding, limiting its usefulness for detailed video analysis. Trials using several coding schema on short video extracts proved excessively cumbersome [^15] [@moncada_should_2025]. To address these limitations, I developed a workaround using VLC Player [^vlc] for dual playback. Coded observations were captured at a limited granularity of five-minute segments. Partial transcription, annotation, and thematic coding were recorded in Word tables, then imported into NVivo for comparison and query generation.

Creating these structured documents for video files of approximately two hours was time consuming but ultimately productive. The integration of 360° video proved particularly valuable in contextualising screen capture footage, offering a more holistic view of interaction. This led to the development of a consistent co-viewing workflow, using VLC Player to synchronise playback of both video types side by side [^16].


![](./Pictures/360_side_by_side_edge.png){width=98%}

Figure 4.x - 360° footage and screen capture side by side (after processing)

To manage the scope of analysis, eight full sessions and three partial sessions were selected for deeper review. Criteria included clarity of audio and visuals, richness of peer and facilitator interaction, and representation of different phases of the intervention. In practice, most of the analysis focused on data from phase P2, as these contained the richest examples of interaction. One session from the end of P2, in particular, stood out due to the complexity of collaboration and the variety of participant roles observed. Transcripts were created in five-minute intervals, pairing 360° footage with screen recordings. These were not fully coded line by line, but were annotated descriptively with researcher memos noting tensions, tool use, gestures, and participant roles. An indicative example of these notes, including observations, reflections, and extracts of dialogue, is included as a table below.

| Timespan           | Content |
|--------------------|---------|
| 15:00.0 - 20:00.0 | Fok -<br><br>Ed is looking for an animation frame already created<br><br>Mark still reading documentation on how to add animation to a character.<br><br>Mark: Quite complicated. But we can do it. But it would mean a lot of mucking around<br>Ed: Ah Er<br>Mark: Which is difficult to do while we’re here. But it’s doable.<br>Mark: It’s like a project in itself really.<br>Ed: Project in itself?<br>Mark: Yeah! (laughing). I just want to know like. We can get him in. So if I ask about the sizing.<br>Ed: Hmmn<br>Mark: I think you can edit the size here.<br>Ed: Why don’t you go here for a computer and you can do that?<br>Mark: Why. What. While you’re doing what?<br>Ed: Um making a sound track or something. I could do something like that.<br>Mark: Ok. Yeah. I’ll see if there’s any more computers in the cupboard.<br><br>Plan – Polish <br>Child Solo – creating assets – |
| 20:00.0 - 25:00.0 | Ed then creates a head – struggling<br>Seems a bit stuck – not able to recreate work<br><br>Making noises to indicate stuckness after 10 mins<br><br>Create – Polish <br>Child Solo – creating assets –<br>Pair – navigating to assets |

<!-- In addition the spreadsheet of analysis structured using Rogoff’s three planes proved useful to document novel instances of activity and in particular emerging tensions in activity as they were documented within. -->

<!-- In this context, the term refers to a segment of recorded participant activity captured via screen recording, typically involving one learner or a pair working at a laptop during a broader workshop session. -->

As this process continued and generated a wealth of potentially useful observations, I began to question the value of transferring data into NVivo as originally anticipated. The technical questions and frustrations with the limitations of NVivo were compounded by more conceptual questions regarding the utility of the quantitative approach it would enable.  Moncada [-@moncada_should_2025 highlights a tendency to get bogged down in coding due to the nature of Nvivo and similar computer applications program to provoke excessive proximity to the data [@moncada_should_2025; humble_qualitative_2012].  Moncada's [-@moncada_should_2025] comparison of excel and Nvivo as tools for qualitative analysis highlights the advantage of spreadsheets to avoid the fragmentation present in Nvivo's workflow, a reflection which I concur with.

In addition, it became clear that the process of working towards a fixed coding frame risked distracting from a more holistic understanding of the learning environment, particularly the emergent, improvisational, and tool-mediated aspects of learner agency [@saldana_coding_2013]. Already by this stage some candidate codes, such as computational and systems thinking, had been de-prioritised due to either their conceptual overlap with existing literature or a lack of richness in the recorded data of this study. Other categories, such as game design stages, became harder to apply consistently across groups and sessions. A rigid schema, in this case, risked missing what was most interesting: the improvised and evolving use of resources, peer scaffolding, and ongoing negotiation of meaning within the making process.

The shift from planned coding to a more interpretive, emergent strategy was not clear cut; it evolved through repeated attempts to organise, code, and revisit earlier transcripts. The process of creating the session annotation documents also informed a selection of shorter episodes within each session which were flagged for deeper treatment in later vignette analysis. The use of Rogoff’s [-@rogoff_observing_1995] three planes of analysis (personal, interpersonal, and cultural) continued to be helpful as a scaffolding framework. I continued to add to the spreadsheet of analysis structured using three foci, documenting in it novel instances of activity, in particular emerging tensions in activity.



In addition, instead of developing a strict taxonomy, the process evolved into analytical thematic clustering via note-taking, sketching of visual models, and consolidation within tabular form in Word documents. These techniques allowed a more flexible process of interpretation in response to the complexity of participant behaviour, tool use, and social interaction. This shift reflected a broader methodological commitment: staying close to the activity as it unfolded, rather than forcing it into predefined analytic categories. The process of trying, adapting, and discarding coding strategies also mirrored the study’s broader design ethos, where tools and structures evolved in response to emergent practice instead of being imposed from above.

This flexibility helped me identify new themes within the data, such as the significance of game design patterns in shaping learner trajectories or the role of peers and parents in scaffolding complex actions. The original research questions were refined. This phase helped surface key areas for Stage 3, including clusters of agency, mediational strategies, and participant repertoires. It also clarified which transcripts and artefacts were most appropriate for deeper interpretation as vignettes. By the end of this stage, the goal had shifted away from quantifying learning behaviours and toward richly describing how learners appropriated tools and reshaped their participation.


### Stage 3 – Interpretive Consolidation

The third and final stage of analysis focused on consolidating insights through detailed, interpretive work. Building on the broad mapping of Stage 1 and the thematic refinement of Stage 2, this phase returned to key segments of data selected for their richness, complexity, and relevance to the evolving research questions. The goal was to generate grounded, contextualised understandings of learner agency, design mediation, and pedagogical interaction. This stage centred on six key vignettes drawn from screen capture and 360-degree video recordings [@barter_i_2000]. These were chosen for their representation of diverse learner roles, visible design decision-making, and interactional dynamics. Full transcriptions were produced for these segments, integrating verbal dialogue, on-screen activity, and embodied communication such as gestures and movement within the learning space.  Viewing the 360° footage alongside the screen capture recordings proved essential in several cases, especially where participants referenced their physical environment or used gesture to support peer explanation [@nemirovsky_gesture_2012]. Gestures were also used often to communicate planned  game movements on screen, or for other on-screen actions or procedures [^crr].

<!-- At my second formal review, my supervisor Ricardo Nemirovsky encouraged a more deliberate integration of gesture analysis. -->

These vignettes were not designed to be representative in a statistical sense, but to offer rich accounts of how specific learners or pairs navigated their tools, peers, and task structures. Each vignette was treated as an episode that could inform the research questions, including how learners asserted agency, interpreted guidance, or adapted resources. Where possible, these micro-analyses were triangulated with post-session interview data, artefacts (such as games created), and reflective journal entries made immediately after facilitation.

AND EXTRACT OF A VIGNETTE IS NOW INCLUDED.



The chapters that follow present the findings of the study in relation to the use of gameplay design patterns and the development of learner agency within an evolving design context. Rather than separating findings and discussion into distinct chapters, the analysis interweaves data, interpretation and design reflection. While this is not a conventional format, it is increasingly common in design-based and sociocultural research, where interventions and insights emerge together in practice. This approach supports closer alignment between evidence and interpretation, allows theoretical ideas to develop alongside real-time analysis, and reflects the iterative and situated nature of the research process. Chapter 5 presents the development of the learning design across phases of delivery via a design narrative. Chapter 6 explores the mediating role of GDPs in shaping participant experience, while Chapter 7 focuses on the development of agency and identity within the learning community.

#### Design narrative as interpretive structure

This stage of analysis was informed by a design narrative approach, which shaped how patterns of contradiction, adaptation, and response were identified across the CGD&P intervention. Rather than organising interpretation strictly by theme or data type, the analysis followed the evolving arc of the learning design, structured around key shifts in practice, tool use, and facilitation across the delivery phases. This approach aligned with the pedagogical logic of the intervention and was supported by journal notes and triangulated with interview data. The narrative structure reflects the ethos of design-based research by documenting iterative, context-responsive design decisions that may be useful to others working in similar settings.


#### Use of 3GAT analysis


### Diagrammatic representations - Drop, move or keep?

To frame the scene within the broader analytic structure of the thesis, the following diagrams represent the activity systems in which this vignette is situated.

The activity system can be seen as a joint activity stemming from the intersection of wider activity systems in Figure 5.broad. This figure is a necessary simplification of the diverse cultural and contextual factors that fed into the shared activity system of the game-making community. As explored in Chapter 3, this activity functioned as a shared object through which different motivations were negotiated through mutual appropriation [@lecusay_telementoring_2015]. Examples of the influence of these wider systems, including playful interactions, parental support, and practical guidance from facilitators, are explored further in Chapters 6 and 7.

![Illustration 5.broad - Broad Environmental Activity Systems](./Pictures/At_dia_3_v3.png){width=95%}

Using a 3GAT lens, the component parts of this shared activity system are represented again in Figure 5.full. This narrower scope takes as its subject the individuals present in the room during the sessions: children, parents, student helpers, and myself as researcher-facilitator.

![Figure 5.full - Activity system 1 - an emerging community of novice game makers creating games as a learning experience](./Pictures/At_dia_1_v5.png){width=95%}

MOVED BIG CHUNK ON GDP TO CH.6.

##### GDPs as a germ cell in design and analysis

A key focus during this stage was to examine the ways game design patterns (GDPs) user employed as mediational strategies. A spreadsheet of thematic codes, begun in Stage 2, was extended to cluster GDP use more systematically across planes of activity (individual, interpersonal, and cultural). Patterns of adaptation and reinterpretation were particularly salient, as learners often modified a pattern’s purpose or linked it to emergent gameplay goals. These shifts were interpreted through a CHAT lens as evidence of agency enacted through tool transformation and appropriation. The findings of this process are described in Chapter 6.

This study identifies gameplay design patterns (GDPs) as a germ cell concept within its methodological and analytical framework. Chapter 4 outlines the development of this concept and its structuring role in the design; Chapter 5 traces how GDPs were introduced and iteratively embedded in response to practical contradictions; and Chapter 6 explores how they mediated participation, creativity, and collaboration across different episodes of activity.

Drawing on principles from third-generation activity theory and design-based research, the process of rising to the concrete is used both analytically and pedagogically. In seeking a germ cell or unit of analysis, the researcher attends to complex, evolving activity to identify a minimal yet generative concept that can support expansive development. 3GAT distinguishes between empirical abstraction, such as categorising observed features of activity, and theoretical abstraction, which helps explain or guide transformation. The identification of GDPs as a germ cell falls into the latter category [@sannino_activity_2011, p.590]. In line with understandings of DBR research outputs, the identification of guiding principles to address tension in the table above, would be expressed as a set of "tentative generalisations" in the form of design heuristics drawn from the analysis of the concrete practices observed [@hoadley_design-based_2022, p.215].

GDPs are understood here not only as practical design elements but also as conceptual tools that link participant action, shared language, and the structure of the learning environment. Their recurring role in shaping trajectories of participation positioned them as an increasingly central organising feature. As the learning environment evolved, pedagogical structures were developed around progressively more complex engagements with GDPs. These supported varied forms of learner participation while maintaining coherence and a manageable technical scope.

Rather than introducing entirely new materials at each phase, the learning design was structured to allow for deepening engagement with GDPs over time. This enabled participants to recognise, use, and eventually adapt or create gameplay patterns, supported by different forms of documentation. From a methodological perspective, the germ cell framing helped interpret how tools and resources mediated activity at different levels of granularity, from individual design actions to broader shifts in the object of community practice.

As later chapters show, GDPs were not fixed instructional tools but mutable artefacts shaped in and through practice. Their value lay not only in the structures they provided but in how they were interpreted, adapted, and occasionally resisted by participants. This reinforced the germ cell’s analytical utility—not as a static unit, but as a dynamic mediator of developmental possibility. Framing GDPs in this way helped make visible the shifting relationship between individual action, shared artefacts, and the broader activity system over time.

#### Analysing learner agency

GREATER FOCUS ON LITERATURE WITH OUT DUPLICATION.
BE CAREFUL ON WHERE ELSE THIS IS EXPLORE.

REFERENCE RQ3

In parallel, the focus of learner agency was developed through close engagement with participant action across different learning contexts. Several vignettes focused on how learners collaborated, made design decisions, and used material and digital tools to shape their contributions. Through this process, my understanding of agency shifted and deepened. It became clear that agency was not a fixed trait but something that emerged through interaction, support, and opportunities to make meaningful choices. These actions were shaped by learners’ prior experiences, the roles they took on, and the changing structure of the sessions.

The later stages of analysis paid close attention to how participants influenced their own learning paths, how they supported each other, and how they responded when things were difficult or unclear. Agency was interpreted as something that could take different forms, such as trying out new ideas, helping others, changing direction, or asserting creative control. To understand this, I looked at humour, spatial positioning, narrative framing, and the use of gesture to support communication and identity.

This view of agency developed gradually through the analysis process, rather than being applied from the start. It was shaped by what was visible in the data and by ongoing questions about how power, choice, and participation played out in practice. These observations provided a way of seeing agency not only in terms of individual skill or autonomy, but also as something built together and shaped by the design itself.

In line with understandings of  double stimulation intervention, some episodes involved participants generating new mediating elements in response to uncertainty or contradiction.

Chapter 7 builds on this analysis in more depth. It focuses on how agency took different forms across the group, and how learners moved between different roles, styles, and strategies. That chapter also links this to wider ideas about identity, collaboration, and the kinds of opportunities that design-based learning can create.

This interpretive work aimed to clarify not only how the learning environment supported certain forms of agency and design fluency, but also what constraints remained. In some vignettes, learners struggled to access tools or articulate their ideas, prompting reflections on inclusion and the role of facilitation. These observations informed both the final conceptual model, developed in Chapter 7, and ongoing questions about how pedagogical environments can be designed to support participation and identity formation via varied approaches.

WHICH STAGE - HOW DOES IT FIT IN?
By the end of this stage, the analysis had shifted from mapping general trends to closely engaging with specific examples that showed tensions, possibilities, and shifts in learner participation. These vignettes became the foundation for articulating the study’s contributions to both theory and practice.



## Researcher stance and interpretive validity

### Triangulation and analytic trustworthiness

To produce findings are contextually valid and socially relevant, pedagogical interventions took place within an CGD&P learning programme in a non-formal educational context shaped by home education practices, local community logistics, and varied participant demographics. This ecological embeddedness shaped recruitment, session scheduling, and the kinds of learning interactions that were possible (covered in a following section). These factors also brought an authenticity that aligns with ecosystem models of learning design [@barnett_ecosystem_2019]  where value is created through contextually relevant pedagogical engagement. My role as both researcher and facilitator was central to achieving this embeddedness within an authentic context and the broader methodological design of the study. I designed each session to serve a dual purpose of data collection and an educational workshop planned and adapted to meet the varied needs of participants. While this dual role introduced challenges such as balancing the requirements of pedagogical intervention with challenged of recognising positionality within observation, it also provided opportunities for sustained engagement, flexible design, and a clearer view of pedagogical evolution in action. The researcher-practitioner stance invites critical reflection on the ethics, logistics, and value of practice-based inquiry. In achieving this balance, I found the detailed descriptions of the motivational and the practical interventions of Fifth Dimension programme research by Cole and others [-@cole_sustaining_2001; -@cole_fifth_2006; -@cole2009designing] particularly valuable.

<!-- AND Stetsenko HERE? -->

Throughout the process, I aimed to recognise and support emergent participant practices, using tools and scaffolds that could adapt dynamically. These choices are revisited across the following findings chapters, which trace how participants responded to, reshaped, and extended the learning environment.


**Validity & rigour - return to positionality**

Addressing validity of data interpretation, the analysis of this research has prioritised ecological validity by studying interactions that emerged in authentic, practice-based contexts, rather than in controlled or experimental conditions. In addition this study adopted a critical stance on objectivist notions of validity, drawing on DBR and activity theory traditions that position the researcher as an active participant in meaning-making. Validity was approached through triangulation across media data formats such as video, interviews, journals and supporting resources, and supported by ongoing reflection and iterative analysis. Following the transformative activist stance [@stetsenko2020radical], validity in this study is grounded in my ethical and practical engagement with participants, and in the co-construction of knowledge aimed at transforming learning relationships and tools. In this process, journal informed reflection played an important role. While not directly analysed alongside participant data, these journal notes informed the design of resources and facilitation strategies. Selected of journal notes  are included in Appendix 4.x [^17] as evidence of the evolving researcher-practitioner role.

### Generalisability and replication

This study does not aim to measure the efficacy of the intervention or to generalise findings in a statistical sense. Instead, it supports the transferability of insights and the replication of tools and design elements. Project artefacts, including template resources, facilitation guides, and open-source tools, are included in the appendices and online repositories. These were created with adaptability in mind, particularly for informal learning contexts or community-led education.

In terms of methodological contribution, the blend of methods and ethos outlined in this chapter offers a potential return to both the DBR and CHAT research communities. Rather than following a predefined applied CHAT methodology such as the Change Laboratory, this study draws on DBR techniques but meets many of the key criteria for formative intervention as articulated by Engeström and Sannino [-@engestrom_methodological_2014]. The process involved tracing systemic tensions, supporting participants in reconfiguring their activity, and attending to signs of transformative agency across phases.

This hybrid approach responds to a key critique of the Helsinki school’s implementation of third-generation activity theory (3GAT). Formative interventions are often seen as time-consuming and dependent on stable, institutionalised stakeholder groups [@spinuzzi_trying_2020-1]. While my approach operated under more flexible, time-bound, and community-led conditions, it still maintained a generative orientation. It focused on identifying contradictions, surfacing agency, and generating change through iterative design cycles. These cycles align more closely with DBR than with the structured protocols of the Change Laboratory, but they are consistent with formative intervention understood more broadly.

This methodology also places particular emphasis on the development of artefacts and facilitation processes as evidence of learning and transformation. Templates, heuristics, and workflows were refined in practice, reflecting ongoing negotiation between design intent and emergent use. In this sense, the artefacts were not only outputs but tools of inquiry and change. Chapter 5 extends the idea of replication through a design narrative, outlining how tools, materials, and pedagogical structures evolved in response to emerging contradictions.

In addition, the study contributes a practical methodology for working with complex video data across screen capture and 360° formats. Conventional qualitative analysis software (e.g. NVivo) proved cumbersome, prompting the development of a custom workflow using open-source tools, manual transcription, and thematic clustering structured by Rogoff’s three planes of analysis. This adaptive process, shaped by the constraints and richness of the data, may offer value to other researchers navigating similarly situated, tool-mediated learning environments. A summary of the video analysis workflow is included in Appendix X.

Taken together, this approach offers both replicable tools and a flexible, generative methodology that supports the kinds of situated, iterative transformation valued within both DBR and CHAT traditions.

Finally, addressing the generalisability of the research process as a whole, I am in agreement with Gutierrez  and Penuel [-@gutierrez_relevance_2014, p 21] who define generalisability "of findings and theories developed through research as contingent on the uptake of research by local actors who must sustain programs". As such, the test for this findings of this research is beyond the scope of this chapter in that it will be dependent on if it will taken up by relevant partners.

<!-- The work of mutual adjustment of powerful interventions and local contexts does not end when the research ends, but sustaining an intervention requires uptake by schools and districts (Coburn, 2003). For us, we define the generalizability of findings and theories developed through research as contingent on the uptake of research by local actors who must sustain programs. Local actors’ productive adaptation of interventions or use of theories from research and the documentation of the work they must do to sustain change are important sources of evidence for generalizability. -->


### Methodological and practical limitations

Several limitations shaped the scope of this research. Interview data was limited in number and timing due to logistical constraints and the emphasis on supporting live sessions. More regular or follow-up interviews might have added further depth. Similarly, while significant video data was collected, only a subset was transcribed or coded in detail, reflecting a necessary trade-off between depth and breadth of analysis.

Demographic information was not formally collected, which limited opportunities to analyse learning in relation to categories such as class, neurodiversity, or ethnicity. This reflected a deliberate effort to avoid over-formalising informal learning contexts, but it also constrained the interpretation of inclusion and representation.

Formal analysis began only after all intervention phases were complete. In retrospect, conducting interim analysis between phases may have enabled more responsive adaptation of the facilitation design. This sequencing choice reflected the project's structure and the intensive nature of facilitation, but it may have reduced opportunities to iteratively refine based on early patterns in the data.

The role of the researcher as facilitator, designer, and analyst brought both opportunities and risks. Some decisions were intuitive, shaped by prior experience in digital learning facilitation. While this raises questions of objectivity, the Transformative Activist Stance frames such positioning not as bias but as part of a legitimate commitment to utilitarian change.

RE-DO THIS PART.
materials trace the development of the intervention and the researcher’s own evolving perspective. These are included to support transparency rather than as direct data sources.

Plans for comprehensive coding using NVivo were revised (see Stage 2). Several predefined categories were collapsed or removed, and the process became increasingly interpretive and inductive. This was in line with the study’s broader DBR orientation, where analytical strategies were refined in response to the needs and limitations of the data and context.

The methodological approach combined principles from the Helsinki School’s interpretation of formative intervention with naturalistic methods of observing practice in situ. Although the study draws on DBR techniques, it also meets many of Engeström and Sannino’s criteria for formative intervention, including attention to systemic tensions, participant reconfiguration of activity, and the surfacing of agency. While not all research decisions can be justified as systematic, they reflect an evolving effort to understand learning as a complex, socially situated process. The design and delivery of the learning intervention itself served as both a context and a method for exploring agency, contradiction, and tool use.

### Wider limitations

Following the guidance of Thomson [@thomson_category_2024], wider limitations are included in this chapter rather than the concluding chapter, in order to avoid disrupting the narrative flow and interpretive focus of those final reflections.
The most substantial limitation is the lack of analytic focus on the efficacy or learning impact of the intervention in relation to specific conceptual goals such as computational thinking, systems thinking, or learners’ use of coding structures. Such a focus would have required either a deeper dive into the existing dataset or the collection of new data, accompanied by additional methods to triangulate learners’ conceptual development. For example, questions such as *to what extent did participants demonstrate systems thinking in their game design?* or *how effectively did specific GDPs support creative problem-solving?* were not explored directly in this phase of the study.

The decision to avoid this direction was shaped by early and sustained guidance from multiple supervisors and aligns with Bakker’s position on the formulation of DBR research questions [@bakker_design_2018]. He argues for the use of exploratory “how” and “what” questions that suit the adaptive, embedded nature of DBR, offering generative insight without overpromising generalisation.

Limitations of the data collected in P4 and P5 were practical in scope, due to space constraints in the room being used and the large volume of existing data from earlier phases. Although not pursued here, a comparative analysis of the different toolsets used across phases could offer further insight into how tool affordances shape learner agency and design trajectories. This may be a useful direction for future work.



## Chapter conclusion

This chapter has outlined the methodological framework underpinning the study, combining a staged analytical process with a reflexive, practice-based approach. The research design evolved iteratively, with analysis, tool development, and facilitation treated as overlapping components of a continuous inquiry. Insights emerged through repeated cycles of observation, reflection, and design response. The approach enabled attention to contradictions, the development of learner agency, and the role of mediating tools, supporting analysis at both individual and community levels. The next chapter builds on this foundation by tracing the development of the CGD&P programme over time. Using a design narrative approach [@hoadley_creating_2002-1], Chapter 5 explores how tensions in the learning environment prompted shifts in goals, tools, and shared practices, and how these changes were introduced and refined across different phases of delivery.


## Footnotes

[^sh]: The number of helpers varied depending on which phase. Five during phase 2 and one during phase 3. Other phases were delivered by myself only.


[^1]: The Software Sustainability Institute (SSI)  defines software sustainability as enabling research software to remain useful and usable over time through good practices, community support, and institutional recognition.

[^2]: One consideration in terms of the longevity of tools being used is to what extent they are controlled by one organisation and if they have a long term commitment to maintaining educational resources.

[^3]: The Funologists strand of the EdLab programme involved playful, tinkering approach to learning coding and other forms of digital production. The EdLab website archive has a record of this event: https://mickfuzz.github.io/edlab/index.html_p=903.html

[^cdj]: Monthly Coder Dojo events in particular were a valuable testing ground in Manchester. See https://mcrcoderdojo.org.uk/ for more information.

[^4]: Home Education Greater Manchester (Facebook group) https://www.facebook.com/groups/313791918658167, Greater Manchester Home Educators (Facebook group) https://www.facebook.com/groups/164014243270, MADCOW (Email group) a large invite-only email group.

[^5]: This message and summaries of the participant information sheets were part of the ethics process of the study (explored in a later section) are included within Appendix A.

[^6]: Glitch games and manual page: https://glitch-game-club.github.io/ggcp/ggc-examples/ https://glitch-game-club.github.io/ggcp/manual/ - See Appendix t.x for full description of learning resources

[^7]: MakeCode is a block-based programming environment created by Microsoft that enables coding through graphical blocks and JavaScript or Python extensions.

[^itch]: There were practical challenges in collecting and maintaining access to these digital artefacts. In 2025, the platform Glitch.com announced it would no longer host user projects. The process has involved the loss of some functionality as described in Appendix.D.1.?
The choices of this intervention and how they compared to the wider aims of software sustainability are outlined in Appendix T.

[^8]: MOVE - To appendix? Glitch migration was needed after glitch.com announced it would stop hosting in July 2025. I responded by downloading HTML, JavaScript, and CSS files for each game, and archiving them in a Git repository. The process of downloading files and reuploading them was made easier by the use of web technology. They are now online here: https://github.com/glitch-game-club/ggcp. The process has involved the loss of some functionality as described in Appendix.D.1.?
The process has involved the loss of some functionality as described in Appendix.D.1.?



[^10]: 360° video captures activity in all directions, offering a full view of group interactions and spatial dynamics. Screen capture video records on-screen actions, allowing analysis of digital tool use and participant choices during game making.

[^36]: This deficit may be due to the technical challenges in preprocessing the 360 video files.

[^11]: To make the files usable in coding software like NVivo, they had to be converted from `.fbr` to `.mp4` format. This conversion process removed some data, such as mouse and keyboard events.

[^12]: This whole process is so demanding in terms of careful file management. Making me create a linux command line toolbox which is included as a technical appendix. [A draft of which is here](https://docs.google.com/document/d/1Y7MsZDY8ofvls5XO7tztSu8KFdClJo09o3qpWOdkb2M/edit?usp=drive_web&ouid=11432580350275268987)

[^13]: In appendix and online as part of the D3 Make code resources here: https://mickfuzz.github.io/makecode-platformer-101/learningDimensions

[^14]: Nvivo software is proprietary and costly, but is provided by my University which also provides training which I attended.

[^15]: The process was tricky due to the deficit of fine control of video playback within Nvivo. This became intolerable and clearly unsustainable for a full process.

[^vlc]: VLC Player is a free, open-source multimedia player that supports a wide range of video formats. It allows for precise playback control and the viewing of multiple video files simultaneously, making it useful for co-analysis of concurrent video files.

[^16]: The process involved a syncronisation process involving adding front padding for the video file that started second chronologically. It is detailed in Appendix X.

[^17]: Sample journal notes scans are available in Appendix 4.x.

[^af]: Anastasia's family's experience is covered in more detail in Chapter 5.

[^crr]: For example in Vignette 4, indication of action of cropping an image using gestures.

[^hci]: HCI (Human–Computer Interaction) refers to the interdisciplinary study of how people interact with digital technologies, focusing on usability, interface design, and the social context of tool use.


[^piv]: These interviewees included informal educators and creative computing practitioners with experience in community-based coding education. They were consulted to understand broader facilitation challenges.



<!-- ## PARTS FROM OTHER CHAPTER THAT ARE USEFUL -->

<!-- To do this it employs an argumentative grammar fusing elements of DBR and CHAT concepts: specifically iterative processes, analysis of emerging tensions between systems elements, a focus on affordances and secondary stimuli (particularly in relation to participant agency), and the process of rising to the concrete through exploration of a germ cell concept. -->

<!-- In 3GAT terminology, the affordances of my design can be framed as a series of secondary stimuli. Sannino [@sannino_principle_2015] highlights the intersection of the use of secondary stimuli by participants and their volitional action or agency. While subsequent chapters explore shifts in the overall structure of participant activity in alignment with concepts of relational and transformative agency,  -->

<!-- DROP?
The emergent and mutual nature of this design process aligns with both DBR and CHAT principles. In this chapter and the previous one, I have described my active role in motivating and supporting an emerging community through iterative phases. The design approach was open and risky, requiring me to rapidly generate new tools in response to changing needs. I was fortunate that the tenacious character of the participants in P1 helped mitigate the challenges posed by the incomplete design.  -->
